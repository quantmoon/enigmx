DATA BUNDLE BACKUP SQL IMPLEMENTATION NET
------------------------------------------

# -*- coding: utf-8 -*-
"""
Created on Fri Sep 11 19:59:46 2020

@author: FRANK

SQL Quantmoon Data Bundle 
--------------------------
"""

import pyodbc
import numpy as np
import pandas as pd
from itertools import chain
from datetime import datetime
from qzipline.utils import compute_vwap
from fracdiff import StationaryFracdiff
from qzipline.utils import (open_zarr, open_zarr_global, 
                            extract_date_available_market)


class QuantmoonSQLManager(object):
    
    def __init__(self, server, database_name, 
                 base_database='TSQL', 
                 vwap=False, globalRange=False, 
                 remote=False, loggin='', access=''):
        
        self.server = server
        self.base_database = base_database
        self.vwap = vwap
        self.globalRange = globalRange
        self.remote = remote
        
        self.loggin = ('Driver={SQL Server};Server='+server+
                       ';Trusted_Connection=yes;')
        
        if self.vwap:
            self.database_name = database_name.upper() + '_VWAP'
        else:
            self.database_name = database_name.upper() + '_NOVWAP'
            
        if self.globalRange:
            self.global_ = '_GLOBAL'
        else:
            self.global_ = '_NOGLOBAL'
            
            
        self.access = ('Driver={SQL Server};Server='+ server +
                       ';Database='+ self.database_name +
                       ';Trusted_Connection=yes;')
        
    def __checkDatabase__(self):
        if self.database_name.lower() == self.base_database.lower():
            raise ValueError(
                "Database name's equivalent already exist. Change it."
                )
            
    def __getTables__(self, cursor): 
        
        statement = 'SELECT name FROM {}.sys.Tables'.format(
                                            self.database_name
                                            )        
        try:
            cursor.execute(statement)
        except:
            raise ValueError (
                "Check 'statement' or SQLDataBase Initialization"
                )
        else:
            return [db[0] for db in cursor] 
    
        
    def __checkTable__(self, cursor, table_name):

        self.tableName = table_name + self.global_
        return self.tableName in self.__getTables__(cursor)
    
    def __configurateTableStatement__(self, 
                                      table_name, 
                                      dictColVal):
        
        __base_statement__ = ('''CREATE TABLE {} ({})''')
        
        sentence_ = ('{} {},' * len(dictColVal))[:-1]
        table_elements = tuple(chain(*dictColVal.items()))
        tablestructure_ = sentence_.format(*table_elements)
        
        self.tableName = table_name + self.global_
        
        return __base_statement__.format(self.tableName, tablestructure_)
    
    def __configurateWrittingInfo__(self, database_name, 
                                    table_name, cursor_):
        
        self.tableName = table_name + self.global_
        
        searchColumnsName = (
            "SELECT COLUMN_NAME FROM {}.INFORMATION_SCHEMA.COLUMNS " 
            "WHERE TABLE_NAME = N'{}'").format(
                            self.database_name, self.tableName
                            )

                
        cursor_.execute(searchColumnsName)
        SQLCOLNAMES = [element[0] for element in cursor_]
        SQLCOLNUM = len(SQLCOLNAMES)
        
        base_values = ("?," * (SQLCOLNUM))[:-1]
        
        insert_ = "INSERT INTO {}.dbo.{}".format(
                                self.database_name, 
                                self.tableName
                                )
        
        _predicative_ = ("{}," * SQLCOLNUM)[:-1]
        predicate_ = _predicative_.format(*SQLCOLNAMES)
        
        values_ = "VALUES ({})".format(base_values)
        
        final_statement = "{} ({}) {}".format(
                                insert_, 
                                predicate_, 
                                values_
                                )
        return final_statement 
            
    def create_new_database(self):
        
        self.__checkDatabase__()
        
        dbconn = pyodbc.connect(self.loggin)
        cursor = dbconn.cursor()
        cursor.execute("SELECT name FROM master.dbo.sysdatabases")
        existence_ = [db[0].lower() for db in cursor]
        
        data_base_name = self.database_name
        
        if data_base_name not in existence_:
            dbconn.autocommit = True
            cursor.execute("CREATE DATABASE [{}]".format(
                                                self.database_name
                                                )
                            )
            print("Database '%s' successfully created" % 
                                          self.database_name
                                          )
            cursor.close()
            dbconn.close()
        else:
            cursor.close()
            dbconn.close()
            raise ValueError(
                "Database name's equivalent already exist. Change it."
                )
            
    def select_database(self):
        
        try: 
            dbconn = pyodbc.connect(self.access)
            cursor = dbconn.cursor()
        except pyodbc.Error as ex:
            print("Error statement appears:{}".format(ex))
            return "Circuit Breaker: Non SQL Connection initialized"
        return dbconn, cursor 
        
    def create_new_table(self, 
                         table_name, 
                         dict_info, 
                         dbconn_, 
                         cursor_):

        if self.__checkTable__(cursor_, table_name):
            raise ValueError(
                    "Table's name already exists. "
                    "Change it or use 'write_table_info()' "
                    "method instead."
                )
        
        statement = self.__configurateTableStatement__(
                                        table_name, dict_info
                                        )
        
        try:
            cursor_.execute(statement)
            dbconn_.commit()
        except pyodbc.Error as ex:
            print("Error statement computation: {}".format(ex))
            return "Breaks: Creating Table Process Failed"
        print("Table '{}' has been successfully created.".format(
                                                        self.tableName
                                                        )
                )
        
    def read_table_info(statement, dbconn_, 
                        cursor_, dataframe=False):
        
        if dataframe==False:
            cursor_.execute(statement)     
            return cursor_
        else:
            sql_query = pd.read_sql_query(statement, dbconn_)
            return sql_query 
        
    
    def get_write_statement(self, database_name, 
                            table_name, cursor_):
        
        return self.__configurateWrittingInfo__(
                                        database_name, 
                                        table_name, 
                                        cursor_
                                        )
        
    def write_table_info(self, statement_, 
                         dbconn_, cursor_, 
                         data_, bartype_,
                         vwap_):
        
        for idx, row in data_.iterrows():
            
            if bartype_=='time' and vwap_:
                cursor_.execute(
                    statement_, row.datetime, row.price
                    )
            elif bartype_=='time' and vwap_==False:
                cursor_.execute(
                    statement_, row.datetime, row.price, row.vol
                    )     
            elif bartype_=='tick' and vwap_:
                cursor_.execute(
                    statement_, row.grpId, row.datetime, row.price
                    )
            elif bartype_=='tick' and vwap_==False:
                cursor_.execute(
                    statement_, row.datetime, row.price
                    )                
            elif bartype_=='fracdiff':
                cursor_.execute(
                    statement_, row.datetime, row.fracdiff
                    )
        dbconn_.commit()
        #cursor_.close()
        print("Information '{}' was written".format(
                                        self.database_name
                                        )
                                    )
      

##############################################################################
                
class DataRespositoryInitialization(object):
    
    def __init__(self, data_dir, stock, 
                 start_date = None, end_date = None):
        
        self.data_dir = data_dir
        self.stock = stock
        self.start_date = start_date
        self.end_date = end_date
        
        if type(self.start_date) != str:
            raise ValueError(
                    'Only string type for start_date and end_date'
                )
        else: 
            if self.end_date==None:
                self.range_dates = [self.start_date]
            else:
                self.range_dates = extract_date_available_market(
                                                    self.start_date,
                                                    self.end_date
                                                    )
                
    def __mainContent__(self, bartype, 
                          time, freq, date, 
                          vwap, window_fracdiff, globalRange):
        
        infoTuple = self.get_zarr_data(
                                date, time, freq, globalRange
                                )
            
        new_dataset = self.bar_calculation(
                                    infoTuple, 
                                    bartype.lower(), 
                                    vwap, 
                                    window_fracdiff
                                    )    
        return new_dataset
                
    def __forwardNanFill__(self, arr):
        
        arr = np.array([arr])
        mask = np.isnan(arr)
        idx = np.where(~mask, np.arange(mask.shape[1]), 0)
        np.maximum.accumulate(idx, axis=1, out=idx)
        out = arr[np.arange(idx.shape[0])[:,None], idx]
        
        return  out.reshape(-1, 1) #out[0,:]
    
    def __dropZeros__(self, tupla):
        for numpy in tupla:
            yield numpy[numpy!=0.0]    
                
    def get_zarr_data(self, date, time, freq, globalRange):
        
        if globalRange:
            data_ = open_zarr_global(
                                self.data_dir+"/"+ self.stock +".zarr", 
                                self.range_dates
                            )

        else: 
            data_ = open_zarr(
                            self.data_dir+"/"+ self.stock +".zarr", 
                            date
                        )
                
        timestamps, price_, vol_ = self.__dropZeros__(
                                            tupla = data_
                                            )
        
        ts_dt = [datetime.fromtimestamp(t) 
                 for t in timestamps/10**3]
        
        #fix inconsistency on data origin
        if price_.shape != vol_.shape:
            difference = abs(
                    price_.shape[0] - vol_.shape[0]
                    )
            
            if price_.shape[0] > vol_.shape[0]:
                price_ = price_[:-difference]
                ts_dt = ts_dt[:-difference]
                
            else:
                price_ = price_[:-difference]
                ts_dt = ts_dt[:-difference]
    
        
        df_ = pd.DataFrame({
                'price':price_,
                'vol':vol_,
                }, index=ts_dt
            )
        
        group_data = df_.resample('{}{}'.format(freq,time) )
        num_time_bars = group_data.ngroups
        total_ticks = price_.shape[0]
        
        return group_data, num_time_bars, df_, total_ticks

    def bar_calculation(self, infoTuple_, 
                        bartype, vwap, 
                        window_fracdiff):
        
        group_data, num_time_bars, df_, total_ticks = (
                                        infoTuple_[0], 
                                        infoTuple_[1], 
                                        infoTuple_[2], 
                                        infoTuple_[3]
                                        )
        #Time Bars
        if bartype=='time':
            
            if vwap==False:
                #compute mean price for each sample frequency
                result_dataset=group_data.mean()
                result_dataset=result_dataset.fillna(
                                            method='ffill'
                                            )
                result_dataset = result_dataset.rename_axis(
                                                    'datetime'
                                                ).reset_index()
                
            else:
                #create VWAP value for each sample frequency
                data_pricetime=group_data['price','vol'].apply(
                                                    compute_vwap
                                                    )
                result_dataset = pd.DataFrame(
                                    {'price':data_pricetime}
                                    )
                result_dataset=result_dataset.fillna(
                                            method='ffill'
                                            )
                result_dataset = result_dataset.rename_axis(
                                                    'datetime'
                                                ).reset_index()
                
        #Tick Bars
        elif bartype=='tick':
            	
                #Conditional output
            if vwap==False:
                #returns the original xarray.Dataset 
                #not for storage; just for print
                #output format: dataFrame
                
                index = group_data.first().index.values
                value = group_data.mean().price.values
                result_dataset = pd.DataFrame(
                                    data={
                                        'datetime':index, 
                                        'price':value
                                        }
                                    )
    
            else:
                
                #calculate the number ticks per bar:
                #total ticks / ticks per bar
                num_ticks_per_bar = total_ticks/num_time_bars   
                
                #round it to the nearest thousand
                num_ticks_per_bar = round(num_ticks_per_bar, -1)
                
                #reset index of data to calculate 'grpId'
                df_ = df_.reset_index()
                
                #calcualte groupId value 
                #column 'index' == range(0,len(d_)) // num ticks per bar 
                df_["grpId"]= df_.index // num_ticks_per_bar
                
                #groupby grpId to categorize groups of density by ticks
                data_grouped = df_.groupby('grpId')
                
                #get first datatime from column of time ('index')
                datetimes_ = data_grouped.first()['index']
                
                #compute vwap to the grouped dataelements by 'grpId'
                data_tick_vwap = data_grouped.apply(
                                            compute_vwap
                                            )
                
                #result_dataset
                result_dataset = pd.concat(
                                    [datetimes_, data_tick_vwap], 
                                        axis=1
                                    )
                
                result_dataset.columns = ["datetime", 
                                          "price"]
                result_dataset = result_dataset.reset_index()
                
                
        elif bartype == 'volume':
            if vwap==False:
                #returns the original xarray.Dataset 
                #not for storage; just for print
                #output format: dataFrame
                
                index = group_data.first().index.values
                value = group_data.mean().price.values
                vol = group_data.mean().vol.values
                result_dataset = pd.DataFrame(
                                    data={
                                        'datetime':index, 
                                        'price':value,
                                        'vol':vol
                                        }
                                    )
            else:
                
                #reset index of data to calculate 'grpId'
                df_ = df_.reset_index()
                
                #volume total cumsum 
                data_cm_vol = df_.assign(cmVol=df_['vol'].cumsum()) 
                
                #total volume 
                total_vol = data_cm_vol.cmVol. values[-1] 
                
                #volume per each bar
                vol_per_bar = total_vol / num_time_bars
                
                #round it to the nearest thousand
                vol_per_bar = round(vol_per_bar, -1)
                
                #total vol per group-bar ID
                df_["grpId"] = data_cm_vol.cmVol // vol_per_bar 
                
                #groupby grpId to categorize groups of density by volume
                data_vol_grp = df_.groupby('grpId')
                
                #get first datetime to construct datafrem
                datetimes_ = data_vol_grp.first()['index']
                
                #vwap over each vol bar group ID
                data_vol_vwap = data_vol_grp.apply(compute_vwap)
                
                #create final dataframe
                result_dataset = pd.concat(
                        [datetimes_, data_vol_vwap], 
                        axis=1
                )
                
                #rename columns
                result_dataset.columns = ["datetime", 
                                          "price"]
                
                result_dataset = result_dataset.reset_index()

            
        elif bartype =='fracdiff':
                #construct the VWAP or series.mean
                if vwap == False:
                    data_pricetime=group_data.mean()
                    data = data_pricetime.price.values 
                else:
                    data_pricetime=group_data['price','vol'].apply(
                                                    compute_vwap
                                                    )
                    data = data_pricetime.values 
                
                #check and fill nan's with previous values (if exits)
                #reshape by ND array being N: N datapoints
                #each value is a dimension: single column array
                X_ = self.__forwardNanFill__(data)
                
                #calculating the stationary version of price series
                #use a windows given as a parameter or default=2
                #the pvalue = 0.01 was set to adjust the fracdiff
                fracdiff_ = StationaryFracdiff(window=window_fracdiff,
                                               pvalue=0.01)
                fracdiff_results = fracdiff_.fit_transform(X_)

                #Drop the 'nan' values where nan's=length of window
                #First 'n' datapoints should be 'nan' if window = n 
                fracdiff_results=fracdiff_results[
                                        ~np.isnan(fracdiff_results)
                                        ]
                
                #Setting the time numpy values series on a variable 
                time_info = data_pricetime.index.values[window_fracdiff-1:]
                result_dataset = pd.DataFrame(
                                        {'fracdiff':fracdiff_results},
                                        index=time_info
                                        )
                
                result_dataset = result_dataset.rename_axis(
                                                    'datetime'
                                                ).reset_index()
        else: 
            raise ValueError(
                    "'bartype' input not recognized."
                )
            
        return result_dataset
        
    def transformation_data(self, bartype, 
                            time='Min', freq=1, 
                            vwap=False, 
                            window_fracdiff=2, globalRange=False):
        
        if globalRange:
            data_ = self.__mainContent__(
                                    bartype, 
                                    time, 
                                    freq, 
                                    self.start_date, 
                                    vwap, 
                                    window_fracdiff, 
                                    globalRange
                                )    
        
        else:
            data_ = pd.concat(
                [self.__mainContent__(
                                bartype, 
                                time, 
                                freq, 
                                date, 
                                vwap, 
                                window_fracdiff, 
                                globalRange
                            ) 
                    for date in self.range_dates]
                )
        
        return data_ 
            
                    
                    
            
        
            
            
    
    